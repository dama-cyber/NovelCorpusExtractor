"""
å‘½ä»¤è¡Œç•Œé¢å·¥å…·
æä¾›å®Œæ•´çš„CLIåŠŸèƒ½ï¼ŒåŒ…æ‹¬å•æ–‡ä»¶å¤„ç†ã€æ‰¹é‡å¤„ç†ã€é…ç½®ç®¡ç†ç­‰
"""

import argparse
import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import List, Optional, Dict, Any

from main import NovelCorpusExtractor
from core.batch_processor import BatchProcessor, create_batch_processor
from core.data_exporter import DataExporter, create_exporter
from core.utils import ensure_dir

logger = logging.getLogger(__name__)


class CLIFormatter:
    """CLIè¾“å‡ºæ ¼å¼åŒ–å™¨"""
    
    @staticmethod
    def success(message: str):
        """æˆåŠŸæ¶ˆæ¯"""
        print(f"âœ… {message}")
    
    @staticmethod
    def error(message: str):
        """é”™è¯¯æ¶ˆæ¯"""
        print(f"âŒ {message}", file=sys.stderr)
    
    @staticmethod
    def info(message: str):
        """ä¿¡æ¯æ¶ˆæ¯"""
        print(f"â„¹ï¸  {message}")
    
    @staticmethod
    def warning(message: str):
        """è­¦å‘Šæ¶ˆæ¯"""
        print(f"âš ï¸  {message}")
    
    @staticmethod
    def progress(message: str):
        """è¿›åº¦æ¶ˆæ¯"""
        print(f"ğŸ”„ {message}")


def setup_logging_for_cli(verbose: bool = False):
    """ä¸ºCLIè®¾ç½®æ—¥å¿—"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler()]
    )


async def process_single_file(
    extractor: NovelCorpusExtractor,
    input_file: str,
    novel_type: str = "é€šç”¨",
    output_dir: Optional[str] = None,
    export: Optional[str] = None,
    export_dir: Optional[str] = None
):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    CLIFormatter.progress(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
    
    try:
        if output_dir:
            extractor.memory_manager.output_dir = Path(output_dir)
            extractor.memory_manager.output_dir.mkdir(parents=True, exist_ok=True)
        
        results = await extractor.process_novel(input_file, novel_type)
        
        chunk_results = results.get("chunk_results", []) if isinstance(results, dict) else results
        CLIFormatter.success(f"å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(chunk_results)} ä¸ªæ–‡æœ¬å—")
        
        if isinstance(results, dict) and results.get("workflow"):
            flows = ", ".join(results["workflow"].keys())
            CLIFormatter.info(f"å·²æ‰§è¡Œçš„å·¥ä½œæµé˜¶æ®µ: {flows}")
        
        CLIFormatter.info(f"è¾“å‡ºç›®å½•: {extractor.memory_manager.output_dir}")
        
        # å¯¼å‡ºæ•°æ®
        if export:
            await export_data(
                extractor,
                results,
                export_format=export,
                export_dir=export_dir or str(extractor.memory_manager.output_dir / "exports")
            )
        
        return results
        
    except KeyboardInterrupt:
        CLIFormatter.warning("ç”¨æˆ·ä¸­æ–­å¤„ç†")
        raise
    except Exception as e:
        CLIFormatter.error(f"å¤„ç†å¤±è´¥: {e}")
        raise


async def process_batch(
    extractor: NovelCorpusExtractor,
    file_paths: List[str],
    novel_type: str = "é€šç”¨",
    max_concurrent: int = 3,
    output_dir: Optional[str] = None
):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
    CLIFormatter.progress(f"åˆ›å»ºæ‰¹é‡ä»»åŠ¡ï¼Œå…± {len(file_paths)} ä¸ªæ–‡ä»¶")
    
    try:
        batch_processor = create_batch_processor(
            extractor,
            max_concurrent=max_concurrent,
            output_dir=Path(output_dir) if output_dir else None
        )
        
        batch_result = batch_processor.create_batch(
            file_paths=file_paths,
            novel_type=novel_type
        )
        
        CLIFormatter.info(f"æ‰¹é‡ä»»åŠ¡ID: {batch_result.batch_id}")
        CLIFormatter.progress("å¼€å§‹æ‰¹é‡å¤„ç†...")
        
        def progress_callback(batch):
            """è¿›åº¦å›è°ƒ"""
            from core.batch_processor import BatchResult
            progress = batch.progress_percentage
            CLIFormatter.progress(
                f"è¿›åº¦: {progress:.1f}% "
                f"({batch.completed_jobs}/{batch.total_jobs} å®Œæˆ, "
                f"{batch.failed_jobs} å¤±è´¥)"
            )
        
        final_result = await batch_processor.process_batch(
            batch_result.batch_id,
            progress_callback=progress_callback
        )
        
        CLIFormatter.success(
            f"æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸ: {final_result.completed_jobs}, "
            f"å¤±è´¥: {final_result.failed_jobs}"
        )
        CLIFormatter.info(f"æˆåŠŸç‡: {final_result.success_rate:.1f}%")
        
        if output_dir:
            summary_file = Path(output_dir) / f"{final_result.batch_id}_summary.json"
            CLIFormatter.info(f"æ‰¹é‡ç»“æœæ‘˜è¦: {summary_file}")
        
        return final_result
        
    except Exception as e:
        CLIFormatter.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        raise


def list_batch_status(batch_id: Optional[str] = None):
    """åˆ—å‡ºæ‰¹é‡ä»»åŠ¡çŠ¶æ€"""
    # æ³¨æ„ï¼šè¿™éœ€è¦ä»å­˜å‚¨ä¸­è¯»å–ï¼Œç®€åŒ–å®ç°
    CLIFormatter.info("æ‰¹é‡ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢åŠŸèƒ½éœ€è¦APIæœåŠ¡å™¨æ”¯æŒ")
    CLIFormatter.info("è¯·ä½¿ç”¨APIç«¯ç‚¹ /api/batch æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€")


def show_config_info(config_path: str):
    """æ˜¾ç¤ºé…ç½®ä¿¡æ¯"""
    import yaml
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f) or {}
        
        CLIFormatter.info("é…ç½®ä¿¡æ¯:")
        print(f"  é…ç½®æ–‡ä»¶: {config_path}")
        
        # æ˜¾ç¤ºæ¨¡å‹é…ç½®
        model_config = config.get("model", {})
        api_pool_config = config.get("api_pool", {})
        
        if api_pool_config.get("enabled", False):
            apis = api_pool_config.get("apis", [])
            enabled_apis = [api for api in apis if api.get("enabled", True)]
            print(f"  APIæ± æ¨¡å¼: å¯ç”¨ ({len(enabled_apis)} ä¸ªAPI)")
            for api in enabled_apis:
                provider = api.get("provider", "unknown")
                name = api.get("name", provider)
                print(f"    - {name} ({provider})")
        else:
            provider = model_config.get("model", "unknown")
            print(f"  æ¨¡å‹: {provider}")
        
        # æ˜¾ç¤ºå…¶ä»–é…ç½®
        output_dir = config.get("output_dir", "output")
        print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        
        chunk_size = config.get("chunk_size", 1024)
        chunk_overlap = config.get("chunk_overlap", 100)
        print(f"  åˆ†å—å¤§å°: {chunk_size}, é‡å : {chunk_overlap}")
        
        topology_mode = config.get("topology", {}).get("mode", "auto")
        print(f"  æ‹“æ‰‘æ¨¡å¼: {topology_mode}")
        
    except Exception as e:
        CLIFormatter.error(f"è¯»å–é…ç½®å¤±è´¥: {e}")


def validate_config(config_path: str) -> bool:
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    CLIFormatter.progress(f"éªŒè¯é…ç½®æ–‡ä»¶: {config_path}")
    
    try:
        extractor = NovelCorpusExtractor(config_path)
        CLIFormatter.success("é…ç½®æ–‡ä»¶æœ‰æ•ˆ")
        return True
    except Exception as e:
        CLIFormatter.error(f"é…ç½®æ–‡ä»¶æ— æ•ˆ: {e}")
        return False


async def export_data(
    extractor: NovelCorpusExtractor,
    results: Dict[str, Any],
    export_format: str = "all",
    export_dir: Optional[str] = None
):
    """å¯¼å‡ºå¤„ç†ç»“æœ"""
    CLIFormatter.progress(f"å¼€å§‹å¯¼å‡ºæ•°æ®ï¼Œæ ¼å¼: {export_format}")
    
    try:
        # ç¡®å®šå¯¼å‡ºç›®å½•
        if export_dir:
            export_path = Path(export_dir)
        else:
            export_path = extractor.memory_manager.output_dir / "exports"
        
        export_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå¯¼å‡ºå™¨
        exporter = create_exporter(export_path)
        
        # å‡†å¤‡æ•°æ®
        export_data_dict = {}
        
        # æ–‡æœ¬å—ç»“æœ
        if isinstance(results, dict):
            if 'chunk_results' in results:
                export_data_dict['chunkResults'] = results['chunk_results']
            if 'outline' in results:
                export_data_dict['outline'] = results['outline']
            if 'workflow' in results:
                export_data_dict['workflow'] = results['workflow']
        else:
            export_data_dict['chunkResults'] = results if isinstance(results, list) else []
        
        # ç”ŸæˆåŸºç¡€æ–‡ä»¶å
        base_filename = f"export_{Path(extractor.memory_manager.output_dir).name}"
        
        # æ ¹æ®æ ¼å¼å¯¼å‡º
        if export_format.lower() == "all":
            exported_files = exporter.export_from_memory_manager(
                extractor.memory_manager,
                chunk_results=export_data_dict.get('chunkResults'),
                outline=export_data_dict.get('outline'),
                workflow_summary=export_data_dict.get('workflow'),
                base_filename=base_filename
            )
            CLIFormatter.success(f"å·²å¯¼å‡ºæ‰€æœ‰æ ¼å¼åˆ°: {export_path}")
            for fmt, path in exported_files.items():
                CLIFormatter.info(f"  {fmt.upper()}: {path}")
        elif export_format.lower() == "json":
            path = exporter.export_json(export_data_dict, base_filename)
            CLIFormatter.success(f"JSONå¯¼å‡ºå®Œæˆ: {path}")
        elif export_format.lower() == "csv":
            if export_data_dict.get('chunkResults'):
                path = exporter.export_csv(export_data_dict['chunkResults'], base_filename)
                CLIFormatter.success(f"CSVå¯¼å‡ºå®Œæˆ: {path}")
            else:
                CLIFormatter.warning("æ²¡æœ‰æ–‡æœ¬å—ç»“æœå¯å¯¼å‡ºä¸ºCSV")
        elif export_format.lower() == "excel":
            if export_data_dict.get('chunkResults'):
                excel_data = {'æ–‡æœ¬å—ç»“æœ': export_data_dict['chunkResults']}
                path = exporter.export_excel(excel_data, base_filename)
                CLIFormatter.success(f"Excelå¯¼å‡ºå®Œæˆ: {path}")
            else:
                CLIFormatter.warning("æ²¡æœ‰æ•°æ®å¯å¯¼å‡ºä¸ºExcel")
        elif export_format.lower() == "markdown":
            path = exporter.export_markdown(export_data_dict, base_filename)
            CLIFormatter.success(f"Markdownå¯¼å‡ºå®Œæˆ: {path}")
        elif export_format.lower() == "html":
            path = exporter.export_html(export_data_dict, base_filename)
            CLIFormatter.success(f"HTMLå¯¼å‡ºå®Œæˆ: {path}")
        else:
            CLIFormatter.error(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")
            CLIFormatter.info("æ”¯æŒçš„æ ¼å¼: json, csv, excel, markdown, html, all")
    
    except Exception as e:
        CLIFormatter.error(f"å¯¼å‡ºå¤±è´¥: {e}")
        if logger.isEnabledFor(logging.DEBUG):
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å°è¯´è¯­æ–™æå–ç³»ç»Ÿ CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªæ–‡ä»¶
  python cli.py process --input novel.txt --type ç„å¹»
  
  # æ‰¹é‡å¤„ç†
  python cli.py batch --files novel1.txt novel2.txt --type è¨€æƒ…
  
  # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
  python cli.py config --show
  
  # éªŒè¯é…ç½®
  python cli.py config --validate
        """
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default="config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # process å‘½ä»¤ï¼šå¤„ç†å•ä¸ªæ–‡ä»¶
    process_parser = subparsers.add_parser("process", help="å¤„ç†å•ä¸ªæ–‡ä»¶")
    process_parser.add_argument("--input", "-i", type=str, required=True, help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    process_parser.add_argument("--output", "-o", type=str, help="è¾“å‡ºç›®å½•")
    process_parser.add_argument("--type", "-t", type=str, default="é€šç”¨", help="å°è¯´ç±»å‹")
    process_parser.add_argument("--export", "-e", type=str, choices=["json", "csv", "excel", "markdown", "html", "all"], help="å¯¼å‡ºæ ¼å¼")
    process_parser.add_argument("--export-dir", type=str, help="å¯¼å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šè¾“å‡ºç›®å½•/exportsï¼‰")
    
    # batch å‘½ä»¤ï¼šæ‰¹é‡å¤„ç†
    batch_parser = subparsers.add_parser("batch", help="æ‰¹é‡å¤„ç†æ–‡ä»¶")
    batch_parser.add_argument("--files", "-f", nargs="+", required=True, help="æ–‡ä»¶è·¯å¾„åˆ—è¡¨")
    batch_parser.add_argument("--output", "-o", type=str, help="è¾“å‡ºç›®å½•")
    batch_parser.add_argument("--type", "-t", type=str, default="é€šç”¨", help="å°è¯´ç±»å‹")
    batch_parser.add_argument("--concurrent", "-c", type=int, default=3, help="æœ€å¤§å¹¶å‘æ•°")
    
    # config å‘½ä»¤ï¼šé…ç½®ç®¡ç†
    config_parser = subparsers.add_parser("config", help="é…ç½®ç®¡ç†")
    config_group = config_parser.add_mutually_exclusive_group(required=True)
    config_group.add_argument("--show", action="store_true", help="æ˜¾ç¤ºé…ç½®ä¿¡æ¯")
    config_group.add_argument("--validate", action="store_true", help="éªŒè¯é…ç½®æ–‡ä»¶")
    
    # status å‘½ä»¤ï¼šçŠ¶æ€æŸ¥è¯¢
    status_parser = subparsers.add_parser("status", help="æŸ¥è¯¢æ‰¹é‡ä»»åŠ¡çŠ¶æ€")
    status_parser.add_argument("--batch-id", type=str, help="æ‰¹é‡ä»»åŠ¡ID")
    
    # export å‘½ä»¤ï¼šå¯¼å‡ºå·²æœ‰ç»“æœ
    export_parser = subparsers.add_parser("export", help="å¯¼å‡ºå¤„ç†ç»“æœ")
    export_parser.add_argument("--output-dir", "-o", type=str, required=True, help="è¾“å‡ºç›®å½•ï¼ˆåŒ…å«å¤„ç†ç»“æœï¼‰")
    export_parser.add_argument("--format", "-f", type=str, choices=["json", "csv", "excel", "markdown", "html", "all"], default="all", help="å¯¼å‡ºæ ¼å¼")
    export_parser.add_argument("--export-dir", type=str, help="å¯¼å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šè¾“å‡ºç›®å½•/exportsï¼‰")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging_for_cli(verbose=args.verbose)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not args.command:
        parser.print_help()
        return
    
    # æ‰§è¡Œå‘½ä»¤
    try:
        if args.command == "process":
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            if not Path(args.config).exists():
                CLIFormatter.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
                return
            
            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
            if not Path(args.input).exists():
                CLIFormatter.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
                return
            
            # åˆ›å»ºæå–å™¨å¹¶å¤„ç†
            extractor = NovelCorpusExtractor(args.config)
            asyncio.run(process_single_file(
                extractor,
                args.input,
                args.type,
                args.output,
                args.export,
                args.export_dir
            ))
        
        elif args.command == "batch":
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            if not Path(args.config).exists():
                CLIFormatter.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
                return
            
            # æ£€æŸ¥æ–‡ä»¶
            valid_files = []
            for file_path in args.files:
                if Path(file_path).exists():
                    valid_files.append(file_path)
                else:
                    CLIFormatter.warning(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
            
            if not valid_files:
                CLIFormatter.error("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯ä»¥å¤„ç†")
                return
            
            # åˆ›å»ºæå–å™¨å¹¶æ‰¹é‡å¤„ç†
            extractor = NovelCorpusExtractor(args.config)
            asyncio.run(process_batch(
                extractor,
                valid_files,
                args.type,
                args.concurrent,
                args.output
            ))
        
        elif args.command == "config":
            if not Path(args.config).exists():
                CLIFormatter.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
                return
            
            if args.show:
                show_config_info(args.config)
            elif args.validate:
                validate_config(args.config)
        
        elif args.command == "status":
            list_batch_status(args.batch_id)
        
        elif args.command == "export":
            # å¯¼å‡ºå·²æœ‰ç»“æœ
            output_dir = Path(args.output_dir)
            if not output_dir.exists():
                CLIFormatter.error(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
                return
            
            # åˆ›å»ºä¸´æ—¶æå–å™¨ä»¥è®¿é—®memory_manager
            extractor = NovelCorpusExtractor(args.config)
            extractor.memory_manager.output_dir = output_dir
            
            # å°è¯•ä»ç»“æœæ–‡ä»¶åŠ è½½æ•°æ®
            chunk_results = []
            outline = None
            workflow_summary = None
            
            # æŸ¥æ‰¾ç»“æœæ–‡ä»¶
            result_files = list(output_dir.glob("*_result.json"))
            if result_files:
                # ä»æœ€æ–°çš„ç»“æœæ–‡ä»¶åŠ è½½
                latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
                CLIFormatter.info(f"ä»æ–‡ä»¶åŠ è½½ç»“æœ: {latest_file}")
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        result_data = json.load(f)
                        chunk_results = result_data.get('chunkResults', result_data.get('chunk_results', []))
                        outline = result_data.get('outline')
                        workflow_summary = result_data.get('workflow')
                    CLIFormatter.success(f"å·²åŠ è½½ {len(chunk_results)} ä¸ªæ–‡æœ¬å—ç»“æœ")
                except Exception as e:
                    CLIFormatter.warning(f"åŠ è½½ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            else:
                CLIFormatter.warning("æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ï¼Œå°†ä»…å¯¼å‡ºè®°å¿†ä½“æ•°æ®")
            
            # æ‰§è¡Œå¯¼å‡º
            asyncio.run(export_data(
                extractor,
                {
                    'chunk_results': chunk_results,
                    'outline': outline,
                    'workflow': workflow_summary
                },
                export_format=args.format,
                export_dir=args.export_dir or str(output_dir / "exports")
            ))
        
    except KeyboardInterrupt:
        CLIFormatter.warning("æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        CLIFormatter.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

